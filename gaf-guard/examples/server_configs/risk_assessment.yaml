inference_engine:
  ollama_llama: &ollama_llama
    class: OllamaInferenceEngine
    model_name_or_path: llama3.2
    credentials:
      api_url: $OLLAMA_API_URL
    parameters:
      num_predict: 1000
      num_ctx: 8192
      temperature: 0.0
      repeat_penalty: 1

  ollama_guardian: &ollama_guardian
    class: OllamaInferenceEngine
    model_name_or_path: granite3-guardian:2b
    credentials:
      api_url: $OLLAMA_API_URL
    parameters:
      num_predict: 1000
      num_ctx: 8192
      temperature: 0.0
      repeat_penalty: 1

  ollama_granite: &ollama_granite
    class: OllamaInferenceEngine
    model_name_or_path: granite3.2:8b
    credentials:
      api_url: $OLLAMA_API_URL
    parameters:
      num_predict: 1000
      num_ctx: 8192
      temperature: 0.0
      repeat_penalty: 1

agents:
  BenchmarkAgent:
    ground_truth: src/gaf_guard/data/ground_truth/customer_complaints.json
  TrialLoggerAgent:
    run_configs:
      trial_dir: trials
      serializer: JSON # YAML, JSON
  OrchestratorAgent:
    RiskGeneratorAgent:
      inference_engine: *ollama_granite
      run_configs:  
        risk_questionnaire_cot: src/gaf_guard/data/chain_of_thought/risk_questionnaire.json
        risk_generation_cot: src/gaf_guard/data/chain_of_thought/risk_generation.json
    HumanInTheLoopAgent: {}
    StreamAgent: {}
    RisksAssessmentAgent:
      inference_engine: *ollama_guardian
    DriftMonitoringAgent:
      inference_engine: *ollama_llama
      run_configs:
        drift_threshold: 2
        drift_monitoring_cot: src/gaf_guard/data/chain_of_thought/drift_monitoring.json

