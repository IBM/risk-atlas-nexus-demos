{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import AgentExecutor, Tool\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "from langgraph.graph import Graph, StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from typing import Dict, List, Optional, Tuple, Annotated\n",
        "\n",
        "# from tools import generate_few_shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Native calls to LLMs.\n",
        "#### The output format is dependent on the LLM chosen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'question': 'For the prompt:What is the weather today?,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Healthcare insurance or (2) other', 'answer': 'other', 'explanation': 'Other since weather has nothing to do with healthcare insurance'}, {'question': 'For the prompt:What is the waste generated at Texas plant last month?,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Waste management or (2) other', 'answer': 'Waste management', 'explanation': 'Waste management since waste information is being retrieved for last month. '}, {'question': 'For the prompt:Can I claim insurance on a direct appointment,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Healthcare insurance or (2) other', 'answer': 'Healthcare insurance', 'explanation': 'Healthcare insurance since the prompt is seeking information on direct appointment insurance'}, {'question': 'For the prompt:Is the world cup match today?,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Waste management or (2) other', 'answer': 'other', 'explanation': 'Other since the prompt talks about world cup match which is independent of waste management'}]\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open(\"../data/drift_monitoring_cot_examples.json\") as f:\n",
        "    cot = json.load(f)\n",
        "print(cot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "usecase = \"Generate personalized, relevant responses, recommendations, and summaries of claims for customers to support agents to enhance their interactions with customers.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Function calling with LLMs.\n",
        "#### The output format should be independent on the LLM chosen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "from langgraph.graph import END, StateGraph\n",
        "from typing import TypedDict\n",
        "from langchain_core.tools import tool\n",
        "from langchain_ollama import ChatOllama\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "\n",
        "ollama = ChatOllama(\n",
        "    model=\"llama3.2\",\n",
        "    temperature=0.0,\n",
        "    num_predict=256,\n",
        "    # other params ...\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class AITaskFormat(BaseModel):\n",
        "    \"\"\"AI Task Format.\"\"\"\n",
        "\n",
        "    answer: str = Field(description=\"AI Tasks\")\n",
        "    question: str = Field(description=\"The question on prompt relevance\")\n",
        "    explanation: int = Field(\n",
        "        description=\"Explanations for why the prompt is relevant or not relevant\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reference: https://blog.gopenai.com/zeroshot-fewshot-and-prompt-chaining-using-langchain-4259d700d67f\n",
        "class FewShot:\n",
        "    def __init__(self):\n",
        "        self.examples = []\n",
        "        self.prefix = f\"\"\"\n",
        "        I want you to play the role of a compliance officer and answer the question\n",
        "        Return the question, answer and explanation in a json format where question, answer and explanation are keys of the json exactly as shown in the examples.\n",
        "        you should answer the question followed by an explanation on how that answer was generated. \n",
        "        \"\"\"\n",
        "\n",
        "    def set_examples(self, examples):\n",
        "        self.examples = examples\n",
        "        return self.examples\n",
        "\n",
        "    def get_examples(self):\n",
        "        return self.examples\n",
        "\n",
        "    def get_example_template(self):\n",
        "        template = \"\"\"\n",
        "        Question: {question}\n",
        "        Answer: {answer}\n",
        "        Explanation: {explanation}\n",
        "        \"\"\"\n",
        "        example_variables = [\"question\", \"answer\", \"explanation\"]\n",
        "        return template, example_variables\n",
        "\n",
        "    def get_prefix(self):\n",
        "        return f\"\"\"\n",
        "        I want you to play the role of a compliance officer and answer the question\n",
        "        Return the question, answer and explanation in a json format where question, answer and explanation are keys of the json exactly as shown in the examples.\n",
        "        you should answer the question followed by an explanation on how that answer was generated. \n",
        "        \"\"\"\n",
        "\n",
        "    def get_suffix(self):\n",
        "        return \"\"\"\n",
        "        Question: {question}\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reference: https://blog.gopenai.com/zeroshot-fewshot-and-prompt-chaining-using-langchain-4259d700d67f\n",
        "\n",
        "import os\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "class FewShotUtility:\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        examples,\n",
        "        prefix,\n",
        "        suffix,\n",
        "        input_variables,\n",
        "        example_template,\n",
        "        example_variables,\n",
        "    ):\n",
        "        self.examples = examples\n",
        "        self.prefix = prefix\n",
        "        self.suffix = suffix\n",
        "        self.input_variables = input_variables\n",
        "        self.example_template = example_template\n",
        "        self.example_variables = example_variables\n",
        "\n",
        "    def get_prompt(self, question):\n",
        "        prompt_template = FewShotPromptTemplate(\n",
        "            examples=self.examples,\n",
        "            example_prompt=self.get_prompt_template(),\n",
        "            prefix=self.prefix,\n",
        "            suffix=self.suffix,\n",
        "            input_variables=self.input_variables,\n",
        "        )\n",
        "        prompt = prompt_template.format(question=question)\n",
        "        return prompt\n",
        "\n",
        "    def get_prompt_template(self):\n",
        "        example_prompt = PromptTemplate(\n",
        "            input_variables=self.example_variables, template=self.example_template\n",
        "        )\n",
        "        return example_prompt\n",
        "\n",
        "    def user_drift_detection(self, prompt):\n",
        "        prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "        message = prompt_template.format_messages()\n",
        "        structured_llm = ollama.with_structured_output(\n",
        "            AITaskFormat, method=\"function_calling\"\n",
        "        )\n",
        "        response = structured_llm.invoke(message)\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "\n",
        "# TypedDict\n",
        "class AITaskFormat(TypedDict):\n",
        "\n",
        "    question: Annotated[str, ..., \"The question and use case of the prompt\"]\n",
        "    answer: Annotated[str, ..., \"Domain for the use case\"]\n",
        "    explanation: Annotated[str, None, \"Explanations for why the domain was selected\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'For the prompt:What is the weather today?,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Healthcare insurance or (2) other',\n",
              "  'answer': 'other',\n",
              "  'explanation': 'Other since weather has nothing to do with healthcare insurance'},\n",
              " {'question': 'For the prompt:What is the waste generated at Texas plant last month?,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Waste management or (2) other',\n",
              "  'answer': 'Waste management',\n",
              "  'explanation': 'Waste management since waste information is being retrieved for last month. '},\n",
              " {'question': 'For the prompt:Can I claim insurance on a direct appointment,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Healthcare insurance or (2) other',\n",
              "  'answer': 'Healthcare insurance',\n",
              "  'explanation': 'Healthcare insurance since the prompt is seeking information on direct appointment insurance'},\n",
              " {'question': 'For the prompt:Is the world cup match today?,Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1)  Waste management or (2) other',\n",
              "  'answer': 'other',\n",
              "  'explanation': 'Other since the prompt talks about world cup match which is independent of waste management'}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fewshot = FewShot()\n",
        "fewshot.set_examples(examples=cot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = [\n",
        "    \"Create a personalized response for a customer who inquired about returning a defective product. The customer's name is 'Emily', and she has made two previous purchases from our company. Please include a summary of the return policy, a recommendation for similar products, and a suggestion for how Emily can proceed with her return\",\n",
        "    \"Generate a summary of claims for a customer who inquired about the 'Eco-Friendly' label on our company's cleaning products. The customer is concerned about the environmental impact of the products and wants to know more about how we ensure sustainability in our manufacturing process\",\n",
        "    \"Create a character profile for a fictional character for my personal venture\",\n",
        "    \"Translate French to English.\",\n",
        "    \"I'm experiencing abdominal pain and vomiting after eating a meal. What could be causing this?\",\n",
        "    \"I'm looking for information on natural remedies for stress relief. Can you recommend any supplements or herbs?\",\n",
        "    \"Recommend a solution for a customer who inquired about replacing a faulty part on their product. The customer has tried troubleshooting but was unable to resolve the issue, and they're concerned that the replacement process will be complicated.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from IPython.display import Image, display\n",
        "\n",
        "\n",
        "# Graph state\n",
        "class AI_TASK(TypedDict):\n",
        "    question: str\n",
        "    answer: str\n",
        "    explanation: str\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    intent: str\n",
        "    drift: AI_TASK\n",
        "    domain: str\n",
        "    prompt: str\n",
        "    drift_value: int\n",
        "    drift_threshold: int\n",
        "\n",
        "\n",
        "# Nodes\n",
        "def setup(state: State):\n",
        "    state[\"drift_value\"] = 0\n",
        "    return state\n",
        "\n",
        "\n",
        "# Nodes\n",
        "def drift_detection(state: State):\n",
        "    examples = fewshot.get_examples()\n",
        "    prefix = fewshot.get_prefix()\n",
        "    suffix = fewshot.get_suffix()\n",
        "    example_template, example_variables = fewshot.get_example_template()\n",
        "    fewShot = FewShotUtility(\n",
        "        examples=examples,\n",
        "        prefix=prefix,\n",
        "        suffix=suffix,\n",
        "        input_variables=[\"question\"],\n",
        "        example_template=example_template,\n",
        "        example_variables=example_variables,\n",
        "    )\n",
        "    for prompt in prompts:\n",
        "        question = (\n",
        "            \"For the prompt: \"\n",
        "            + prompt\n",
        "            + \" Consider a binary text classification problem. which class does the prompt belong? Strictly choose one of the two classes. The options are: (1) \"\n",
        "            + state[\"domain\"]\n",
        "            + \" or (2) other\"\n",
        "        )\n",
        "        prompt = fewShot.get_prompt(question)\n",
        "        msg = fewShot.user_drift_detection(prompt)\n",
        "        if \"other\" == msg[\"answer\"]:\n",
        "            state[\"drift_value\"] = state[\"drift_value\"] + 1\n",
        "        else:\n",
        "            state[\"drift_value\"] = state[\"drift_value\"]\n",
        "\n",
        "        print(\n",
        "            msg,\n",
        "            \"\\nNumber of drifts: \" + str(state[\"drift_value\"]),\n",
        "        )\n",
        "    return {\"drift_value\": state[\"drift_value\"]}\n",
        "\n",
        "\n",
        "def incident_reporting(state: State):\n",
        "    if state[\"drift_value\"] > state[\"drift_threshold\"]:\n",
        "        incident_report = (\n",
        "            \"Alert: Potential drift in prompts identified.\\nDrift Threshold: \"\n",
        "            + str(state[\"drift_threshold\"])\n",
        "            + \"\\nNumber of identified drifts: \"\n",
        "            + str(state[\"drift_value\"])\n",
        "            + \"\\n\"\n",
        "        )\n",
        "        print(\"\\n---------\\n\")\n",
        "        print(incident_report)\n",
        "        print(\"\\n---------\\n\")\n",
        "\n",
        "    else:\n",
        "        incident_report = \"None\"\n",
        "        print(\"No drift detected\\n\")\n",
        "    return {\"incident_report\": incident_report}\n",
        "\n",
        "\n",
        "# Build workflow\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"setup\", setup)\n",
        "workflow.add_node(\"drift_detection\", drift_detection)\n",
        "workflow.add_node(\"incident_reporting\", incident_reporting)\n",
        "\n",
        "\n",
        "# Add edges to connect nodes\n",
        "workflow.add_edge(START, \"setup\")\n",
        "workflow.add_edge(\"setup\", \"drift_detection\")\n",
        "workflow.add_edge(\"drift_detection\", \"incident_reporting\")\n",
        "\n",
        "workflow.add_edge(\"incident_reporting\", END)\n",
        "\n",
        "# Compile\n",
        "chain = workflow.compile()\n",
        "\n",
        "# Show workflow\n",
        "display(Image(chain.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Check drift in prompts:\n",
            "\n",
            "--- --- ---\n",
            "\n",
            "{'answer': 'customer claims', 'explanation': 'The prompt belongs to the class of customer claims because it involves a specific inquiry from a customer regarding a return of a defective product, which is a common scenario in customer service.', 'question': 'For the prompt:Create a personalized response for a customer who inquired about returning a defective product. The customer'} \n",
            "Number of drifts: 0\n",
            "{'answer': 'customer claims', 'explanation': 'The answer was generated based on the classification of the prompt as a customer-related claim, indicating that it belongs to the category of customer claims.', 'question': 'For the prompt: Generate a summary of claims for a customer who inquired about the '} \n",
            "Number of drifts: 0\n",
            "{'answer': 'other', 'explanation': 'The prompt does not contain any specific keywords related to healthcare insurance, waste management, or customer claims, which are the primary focus areas of these industries. Therefore, it is classified as &quot;other&quot;.', 'question': 'Create a character profile for a fictional character for my personal venture'} \n",
            "Number of drifts: 1\n",
            "{'answer': 'other', 'explanation': 'The prompt does not specify a specific task related to healthcare insurance, waste management, or customer claims, so it belongs to the category of other.', 'question': 'Translate French to English.'} \n",
            "Number of drifts: 2\n",
            "{'answer': 'customer claims', 'explanation': 'The prompt contains the phrases ', 'question': 'I'} \n",
            "Number of drifts: 2\n",
            "{'answer': 'other', 'explanation': 'The prompt does not contain any specific keywords related to healthcare insurance, such as ', 'properties': {'answer': 'string', 'description': 'The question and use case of the prompt', 'explanation': 'The answer was generated based on the lack of relevant keywords in the prompt.', 'question': 'string'}, 'question': 'I'} \n",
            "Number of drifts: 3\n",
            "{'answer': 'customer claims', 'explanation': 'The answer is classified as customer claims because the prompt describes a specific situation where a customer is seeking assistance with a replacement process, indicating that the customer is making a claim or request for help.', 'question': 'For the prompt:Recommend a solution for a customer who inquired about replacing a faulty part on their product. The customer has tried troubleshooting but was unable to resolve the issue, and they'} \n",
            "Number of drifts: 3\n",
            "\n",
            "---------\n",
            "\n",
            "Alert: Potential drift in prompts identified.\n",
            "Drift Threshold: 2\n",
            "Number of identified drifts: 3\n",
            "\n",
            "\n",
            "---------\n",
            "\n",
            "\n",
            "--- --- ---\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Invoke\n",
        "print(\"Check drift in prompts:\")\n",
        "print(\"\\n--- --- ---\\n\")\n",
        "state = chain.invoke(\n",
        "    {\"drift_threshold\": 2, \"intent\": usecase, \"domain\": \"customer claims\"}\n",
        ")\n",
        "print(\"\\n--- --- ---\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNVz/E2qM0ep8akvseANEhB",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "agentic",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
